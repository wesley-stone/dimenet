{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import string\n",
    "import random\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from dimenet.model.dimenet import DimeNet\n",
    "from dimenet.model.dimenet_pp import DimeNetPP\n",
    "from dimenet.model.activations import swish\n",
    "from dimenet.training.trainer import Trainer\n",
    "from dimenet.training.metrics import Metrics\n",
    "from dimenet.training.data_container import DataContainer\n",
    "from dimenet.training.data_provider import DataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s (%(levelname)s): %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "tf.get_logger().setLevel('WARN')\n",
    "tf.autograph.set_verbosity(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.yaml for DimeNet, config_pp.yaml for DimeNet++\n",
    "with open('config_dye.yaml', 'r') as c:\n",
    "    config = yaml.safe_load(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config['model_name']\n",
    "\n",
    "if model_name == \"dimenet\":\n",
    "    num_bilinear = config['num_bilinear']\n",
    "elif model_name == \"dimenet++\":\n",
    "    out_emb_size = config['out_emb_size']\n",
    "    int_emb_size = config['int_emb_size']\n",
    "    basis_emb_size = config['basis_emb_size']\n",
    "    extensive = config['extensive']\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model name: '{model_name}'\")\n",
    "    \n",
    "emb_size = config['emb_size']\n",
    "num_blocks = config['num_blocks']\n",
    "\n",
    "num_spherical = config['num_spherical']\n",
    "num_radial = config['num_radial']\n",
    "output_init = config['output_init']\n",
    "\n",
    "cutoff = config['cutoff']\n",
    "envelope_exponent = config['envelope_exponent']\n",
    "\n",
    "num_before_skip = config['num_before_skip']\n",
    "num_after_skip = config['num_after_skip']\n",
    "num_dense_output = config['num_dense_output']\n",
    "\n",
    "num_train = config['num_train']\n",
    "num_valid = config['num_valid']\n",
    "data_seed = config['data_seed']\n",
    "dataset_path = config['dataset']\n",
    "\n",
    "batch_size = config['batch_size']\n",
    "\n",
    "#####################################################################\n",
    "# Change this if you want to predict a different target, e.g. to ['U0']\n",
    "# (but don't forget to change output_init as well)\n",
    "targets = config['targets']\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_container = DataContainer(dataset_path, cutoff=cutoff, target_keys=targets)\n",
    "\n",
    "# Initialize DataProvider (splits dataset into training, validation and test set based on data_seed)\n",
    "data_provider = DataProvider(data_container, num_train, num_valid, batch_size,\n",
    "                             seed=data_seed, randomized=True)\n",
    "\n",
    "# Initialize datasets\n",
    "dataset = data_provider.get_dataset('test').prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"dimenet\":\n",
    "    model = DimeNet(\n",
    "            emb_size=emb_size, num_blocks=num_blocks, num_bilinear=num_bilinear,\n",
    "            num_spherical=num_spherical, num_radial=num_radial,\n",
    "            cutoff=cutoff, envelope_exponent=envelope_exponent,\n",
    "            num_before_skip=num_before_skip, num_after_skip=num_after_skip,\n",
    "            num_dense_output=num_dense_output, num_targets=len(targets),\n",
    "            activation=swish, output_init=output_init)\n",
    "elif model_name == \"dimenet++\":\n",
    "    model = DimeNetPP(\n",
    "            emb_size=emb_size, out_emb_size=out_emb_size,\n",
    "            int_emb_size=int_emb_size, basis_emb_size=basis_emb_size,\n",
    "            num_blocks=num_blocks, num_spherical=num_spherical, num_radial=num_radial,\n",
    "            cutoff=cutoff, envelope_exponent=envelope_exponent,\n",
    "            num_before_skip=num_before_skip, num_after_skip=num_after_skip,\n",
    "            num_dense_output=num_dense_output, num_targets=len(targets),\n",
    "            activation=swish, extensive=extensive, output_init=output_init)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model name: '{model_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load weights from model at best step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f85b8679310>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Load the trained model from your own training run\n",
    "directory = \"/path/to/log/dir\"  # Fill this in\n",
    "best_ckpt_file = os.path.join(directory, 'best', 'ckpt')\n",
    "#####################################################################\n",
    "# Uncomment this if you want to use a pretrained model\n",
    "directory = f\"pretrained/dimenet_pp/{targets[0]}\"\n",
    "best_ckpt_file = os.path.join(directory, 'ckpt')\n",
    "#####################################################################\n",
    "\n",
    "model.load_weights(best_ckpt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize aggregates\n",
    "metrics = Metrics('val', targets)\n",
    "preds_total = np.zeros([data_provider.nsamples['test'], len(targets)], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eb589f3d37420196128df68f7a77ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=339.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = int(np.ceil(data_provider.nsamples['test'] / batch_size))\n",
    "\n",
    "for step in tqdm(range(steps_per_epoch)):\n",
    "    preds = trainer.predict_on_batch(dataset_iter, metrics)\n",
    "    \n",
    "    # Update predictions\n",
    "    batch_start = step * batch_size\n",
    "    batch_end = min((step + 1) * batch_size, data_provider.nsamples['test'])\n",
    "    preds_total[batch_start:batch_end] = preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U0 MAE: 0.006319692824035883\n",
      "U0 logMAE: -5.064084529876709\n"
     ]
    }
   ],
   "source": [
    "print(f\"{','.join(targets)} MAE: {metrics.mean_mae}\")\n",
    "print(f\"{','.join(targets)} logMAE: {metrics.mean_log_mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
